{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "from recsys import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "transactions = pd.read_csv(config.RAW_DATA_DIR / 'transactions.csv')\n",
    "\n",
    "# Преобразование столбца t_dat в формат временной метки\n",
    "transactions['t_dat'] = pd.to_datetime(transactions['t_dat'])\n",
    "\n",
    "# Сортировка по значению t_dat\n",
    "transactions = transactions.sort_values(by='t_dat')\n",
    "\n",
    "# Группировка по customer_id и создание списка покупок\n",
    "grouped_transactions = transactions.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "\n",
    "# Переименование столбца\n",
    "grouped_transactions.columns = ['customer_id', 'articles']\n",
    "\n",
    "# Сохранение отфильтрованного датасета\n",
    "grouped_transactions.to_csv('grouped_transactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сортировка по customer_id и создание списка покупок\n",
    "grouped_transactions = grouped_transactions.groupby('customer_id')['articles'].apply(list).reset_index()\n",
    "\n",
    "# Переименование столбца\n",
    "grouped_transactions.columns = ['customer_id', 'articles']\n",
    "\n",
    "# Длина последовательности, минимальное количество истории и размер шага окна\n",
    "sequence_length = 4\n",
    "min_history = 1\n",
    "step_size = 2\n",
    "\n",
    "# Функция для создания последовательностей с использованием скользящего окна\n",
    "def create_sequences(values, window_size, step_size, min_history):\n",
    "    sequences = []\n",
    "    start_index = 0\n",
    "    while len(values[start_index:]) > min_history:\n",
    "        seq = values[start_index : start_index + window_size]\n",
    "        sequences.append(seq)\n",
    "        start_index += step_size\n",
    "    return sequences\n",
    "\n",
    "# Применение функции для создания последовательностей\n",
    "grouped_transactions['articles'] = grouped_transactions['articles'].apply(\n",
    "    lambda ids: create_sequences(ids[0], sequence_length, step_size, min_history)\n",
    ")\n",
    "\n",
    "# Разделение под-последовательностей\n",
    "grouped_transactions_transformed = grouped_transactions.explode('articles', ignore_index=True)\n",
    "\n",
    "# Переименование столбца\n",
    "grouped_transactions_transformed.rename(\n",
    "    columns={'articles': 'sequence_articles'},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Сохранение преобразованных данных\n",
    "grouped_transactions_transformed.to_csv(config.PROCESSED_DATA_DIR / \"grouped_transactions_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Случайный выбор для разделения данных\n",
    "random_selection = np.random.rand(len(grouped_transactions_transformed.index)) <= 0.85\n",
    "\n",
    "# Разделение данных на тренировочные\n",
    "df_train_data = grouped_transactions_transformed[random_selection]\n",
    "train_data_raw = df_train_data[[\"customer_id\", \"sequence_articles\"]].values\n",
    "\n",
    "# Разделение данных на тестовые\n",
    "df_test_data = grouped_transactions_transformed[~random_selection]\n",
    "test_data_raw = df_test_data[[\"customer_id\", \"sequence_articles\"]].values\n",
    "\n",
    "# Сохранение тренировочных и тестовых данных\n",
    "np.save(config.PROCESSED_DATA_DIR / \"train_data_raw.npy\", train_data_raw)\n",
    "np.save(config.PROCESSED_DATA_DIR / \"test_data_raw.npy\", test_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.PROCESSED_DATA_DIR / \"grouped_transactions_transformed.csv\")\n",
    "\n",
    "# Преобразование данных в нужный формат\n",
    "data = df[['customer_id', 'sequence_articles']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словарей для преобразования идентификаторов в индексы\n",
    "article_vocab = set()\n",
    "customer_vocab = set()\n",
    "for customer_id, articles in data:\n",
    "    customer_vocab.add(customer_id)\n",
    "    if isinstance(articles, str):\n",
    "        articles = eval(articles)\n",
    "    if isinstance(articles, list):\n",
    "        for article_list in articles:\n",
    "            if isinstance(article_list, list):\n",
    "                for article in article_list:\n",
    "                    article_vocab.add(article)\n",
    "            else:\n",
    "                article_vocab.add(article_list)\n",
    "\n",
    "article_vocab_stoi = {article: idx for idx, article in enumerate(article_vocab, start=1)}\n",
    "article_vocab_stoi['<unk>'] = 0\n",
    "customer_vocab_stoi = {customer: idx for idx, customer in enumerate(customer_vocab, start=1)}\n",
    "\n",
    "# Pytorch Dataset для взаимодействий пользователей\n",
    "class TransactionSeqDataset(Dataset):\n",
    "    def __init__(self, data, article_vocab_stoi, customer_vocab_stoi):\n",
    "        self.data = data\n",
    "        self.article_vocab_stoi = article_vocab_stoi\n",
    "        self.customer_vocab_stoi = customer_vocab_stoi\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        customer, article_sequence = self.data[idx]\n",
    "        if isinstance(article_sequence, str):\n",
    "            article_sequence = eval(article_sequence)\n",
    "        article_data = [self.article_vocab_stoi.get(item, 0) for sublist in article_sequence for item in sublist]\n",
    "        customer_data = self.customer_vocab_stoi[customer]\n",
    "        return torch.tensor(article_data), torch.tensor(customer_data)\n",
    "\n",
    "# Функция для объединения батчей и добавления паддинга\n",
    "def collate_batch(batch):\n",
    "    article_list = [item[0] for item in batch]\n",
    "    customer_list = [item[1] for item in batch]\n",
    "    return pad_sequence(article_list, padding_value=article_vocab_stoi['<unk>'], batch_first=True), torch.stack(customer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model  # Добавляем атрибут d_model\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe[:, :x.size(1)] / math.sqrt(self.d_model)\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cola(nn.Module):\n",
    "    def __init__(self, lr=0.001, use_pretrained=False, dropout=0.2, d_model=128, n_vocab=30522, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.d_model = d_model\n",
    "        self.n_vocab = n_vocab\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "        self.item_embeddings = nn.Embedding(self.n_vocab, self.d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model=self.d_model, dropout=self.dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=4, dropout=self.dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
    "        self.output_layer = nn.Linear(self.d_model, self.n_vocab)\n",
    "\n",
    "    def encode_text(self, x):\n",
    "        x = self.item_embeddings(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.item_embeddings(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self,  cola: Cola, ntoken: int, nuser: int, d_model: int, nhead: int, d_hid: int, nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.movie_embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.user_embedding = nn.Embedding(nuser, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(2 * d_model, ntoken)\n",
    "        self.init_weights()\n",
    "        self.cola = cola\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.movie_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.user_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, user: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        movie_embed = self.movie_embedding(src) * math.sqrt(self.d_model)\n",
    "        user_embed = self.user_embedding(user) * math.sqrt(self.d_model)\n",
    "        movie_embed = self.pos_encoder(movie_embed)\n",
    "        output = self.transformer_encoder(movie_embed, src_mask)\n",
    "        user_embed = user_embed.expand(-1, output.size(1), -1)\n",
    "        output = torch.cat((output, user_embed), dim=-1)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1566/3387609726.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cola.load_state_dict(state_dict=torch.load(\"../models/model_0_2705_0_1933.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cola(\n",
       "  (item_embeddings): Embedding(30522, 128)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola = Cola(lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cola.load_state_dict(state_dict=torch.load(\"../models/model_0_2705_0_1933.pth\", map_location=device))\n",
    "\n",
    "cola.to(device)\n",
    "\n",
    "cola.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 10, 10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etarasov/.cache/pypoetry/virtualenvs/recsys-u-cwKRDF-py3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "BATCH_SIZE = 256\n",
    "ntoken = 10000  # Примерное количество уникальных фильмов\n",
    "nuser = 1000    # Примерное количество уникальных пользователей\n",
    "d_model = 128\n",
    "nhead = 4\n",
    "d_hid = 512\n",
    "nlayers = 4\n",
    "dropout = 0.2\n",
    "\n",
    "model = TransformerModel(cola, ntoken, nuser, d_model, nhead, d_hid, nlayers, dropout)\n",
    "\n",
    "# Пример данных\n",
    "src = torch.randint(0, ntoken, (BATCH_SIZE, 10))  # Пример последовательностей фильмов\n",
    "user = torch.randint(0, nuser, (BATCH_SIZE, 1))   # Пример пользователей\n",
    "\n",
    "output = model(src, user)\n",
    "print(output.shape)  # Ожидаемый вывод: (BATCH_SIZE, 10, ntoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словарей для преобразования идентификаторов в индексы\n",
    "article_vocab = set()\n",
    "customer_vocab = set()\n",
    "for customer_id, articles in data:\n",
    "    customer_vocab.add(customer_id)\n",
    "    if isinstance(articles, list):\n",
    "        for article in articles:\n",
    "            article_vocab.add(article)\n",
    "\n",
    "article_vocab_stoi = {article: idx for idx, article in enumerate(article_vocab, start=1)}\n",
    "article_vocab_stoi['<unk>'] = 0\n",
    "customer_vocab_stoi = {customer: idx for idx, customer in enumerate(customer_vocab, start=1)}\n",
    "\n",
    "# Pytorch Dataset для взаимодействий пользователей\n",
    "class TransactionSeqDataset(Dataset):\n",
    "    def __init__(self, data, article_vocab_stoi, customer_vocab_stoi):\n",
    "        self.data = data\n",
    "        self.article_vocab_stoi = article_vocab_stoi\n",
    "        self.customer_vocab_stoi = customer_vocab_stoi\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        customer, article_sequence = self.data[idx]\n",
    "        article_data = [self.article_vocab_stoi.get(item, 0) for item in article_sequence]\n",
    "        customer_data = self.customer_vocab_stoi[customer]\n",
    "        return torch.tensor(article_data), torch.tensor(customer_data)\n",
    "\n",
    "# Функция для объединения батчей и добавления паддинга\n",
    "def collate_batch(batch):\n",
    "    article_list = [item[0] for item in batch]\n",
    "    customer_list = [item[1] for item in batch]\n",
    "    return pad_sequence(article_list, padding_value=article_vocab_stoi['<unk>'], batch_first=True), torch.stack(customer_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "# Создание экземпляров Dataset для каждого набора данных\n",
    "train_dataset = TransactionSeqDataset(train_data_raw, article_vocab_stoi, customer_vocab_stoi)\n",
    "val_dataset = TransactionSeqDataset(test_data_raw, article_vocab_stoi, customer_vocab_stoi)\n",
    "\n",
    "# Создание DataLoader\n",
    "train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "val_iter = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_iter, epoch) -> None:\n",
    "    # Переключение в режим обучения\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    for i, [movie_data, user_data] in enumerate(train_iter):\n",
    "        # Загрузка данных\n",
    "        movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
    "        user_data = user_data.reshape(-1, 1)\n",
    "\n",
    "        # Разделение последовательности фильмов на входы и цели\n",
    "        inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
    "        targets_flat = targets.reshape(-1)\n",
    "\n",
    "        # Предсказание фильмов\n",
    "        output = model(inputs, user_data)\n",
    "        output_flat = output.reshape(-1, ntoken)\n",
    "        \n",
    "        # Обратное распространение ошибки\n",
    "        loss = criterion(output_flat, targets_flat)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        # Результаты\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, val_iter) -> float:\n",
    "    # Переключение в режим оценки\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for movie_data, user_data in val_iter:\n",
    "            movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
    "            user_data = user_data.reshape(-1, 1)\n",
    "            inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
    "            targets_flat = targets.reshape(-1)\n",
    "            output = model(inputs, user_data)\n",
    "            output_flat = output.reshape(-1, ntoken)\n",
    "            loss = criterion(output_flat, targets_flat)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_iter)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m89\u001b[39m)\n",
      "Cell \u001b[0;32mIn[85], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_iter, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m log_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m      6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovie_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Загрузка данных\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmovie_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmovie_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/recsys-u-cwKRDF-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/recsys-u-cwKRDF-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/recsys-u-cwKRDF-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/recsys-u-cwKRDF-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[81], line 26\u001b[0m, in \u001b[0;36mTransactionSeqDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     25\u001b[0m     customer, article_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 26\u001b[0m     article_data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marticle_vocab_stoi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marticle_sequence\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m     customer_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustomer_vocab_stoi[customer]\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(article_data), torch\u001b[38;5;241m.\u001b[39mtensor(customer_data)\n",
      "Cell \u001b[0;32mIn[81], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     25\u001b[0m     customer, article_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 26\u001b[0m     article_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marticle_vocab_stoi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m article_sequence]\n\u001b[1;32m     27\u001b[0m     customer_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustomer_vocab_stoi[customer]\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(article_data), torch\u001b[38;5;241m.\u001b[39mtensor(customer_data)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_iter, epoch)\n",
    "    val_loss = evaluate(model, val_iter)\n",
    "    print('-' * 89)\n",
    "    print(f'| end of epoch {epoch:3d} | valid loss {val_loss:5.2f} | valid ppl {math.exp(val_loss):8.2f}')\n",
    "    print('-' * 89)\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys-u-cwKRDF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
